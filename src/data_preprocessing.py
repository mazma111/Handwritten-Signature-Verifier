# -*- coding: utf-8 -*-

"""
CEDAR Signature Dataset Preprocessing Pipeline
==============================================

This module handles preprocessing for the CEDAR signature verification dataset.

USE CASE 1: Generating Dataset Exports for Model Training
----------------------------------------------------------
Run the entire notebook/script to:
1. Load raw CEDAR signatures from genuine_dir and forged_dir
2. Apply preprocessing pipeline (blur → threshold → resize)
3. Create writer-independent train/val/test splits (70/15/15)
4. Save splits.pkl containing file paths and labels for each split
5. Create datasets and dataloaders ready for model training

Key outputs:
- splits.pkl: Contains train/val/test file lists and writer assignments
- train_loader, val_loader, test_loader: PyTorch dataloaders for training

USE CASE 2: Preprocessing Input for Deployment
-----------------------------------------------
For inference on new signatures:
1. Import the preprocess_signature() function
2. Call: preprocessed_img = preprocess_signature(img_path, target_size=(150, 220))
3. Apply same normalization transforms used during training
4. Feed to trained model for prediction

Example:
    from this_module import preprocess_signature
    import torchvision.transforms as transforms
    
    # Preprocess new signature
    img = preprocess_signature('new_signature.png', (150, 220))
    
    # Apply training transforms
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])
    tensor = transform(img).unsqueeze(0)  # Add batch dimension
    
    # Run inference
    prediction = model(tensor)

Note: For deployment, you only need preprocess_signature() and the normalization
transforms. The dataset splitting and dataloader creation are training-only steps.
"""

import os
import cv2
import pickle
import random
import shutil
import zipfile
from PIL import Image
from collections import defaultdict

import torch
from torch.utils import data
import torchvision.transforms as transforms

import matplotlib.pyplot as plt

# Set seeds for reproducibility
SEED = 42
torch.manual_seed(SEED)
random.seed(SEED)

# Configuration
CONFIG = {
    'data_dir': '../datasets/CEDAR',
    'genuine_dir': '../datasets/CEDAR/original',
    'forged_dir': '../datasets/CEDAR/forged',
    'processed_dir': '../datasets/CEDAR/processed',
    'split_dir': '../datasets/CEDAR/split',
    'img_size': (150, 220),  # (height, width)
    'batch_size': 32,
    'num_workers': 2,
    'train_ratio': 0.7,
    'val_ratio': 0.15,
    'test_ratio': 0.15,
}

print("Configuration loaded successfully")
print(f"Image size: {CONFIG['img_size']}")
print(f"Batch size: {CONFIG['batch_size']}")

# **Dataset Verification**

def verify_dataset(genuine_dir, forged_dir):
    # Verify dataset exists and count samples

    # Check directories exist
    if not os.path.exists(genuine_dir):
        raise FileNotFoundError(f"Genuine directory not found: {genuine_dir}")
    if not os.path.exists(forged_dir):
        raise FileNotFoundError(f"Forged directory not found: {forged_dir}")

    # Count files
    genuine_files = [f for f in os.listdir(genuine_dir) if f.endswith('.png')]
    forged_files = [f for f in os.listdir(forged_dir) if f.endswith('.png')]

    print("=" * 50)
    print("DATASET VERIFICATION")
    print("=" * 50)
    print(f"Genuine signatures: {len(genuine_files)}")
    print(f"Forged signatures:  {len(forged_files)}")
    print(f"Total samples:      {len(genuine_files) + len(forged_files)}")
    print("=" * 50)

    # Extract unique writers
    writers = set()
    for f in genuine_files:
        parts = f.replace('.png', '').split('_')
        if len(parts) >= 2:
            writers.add(int(parts[1]))

    print(f"Number of writers: {len(writers)}")
    print(f"Expected: 55 writers × 24 samples × 2 types = 2640 total")
    print("=" * 50)

    return genuine_files, forged_files, sorted(writers)

genuine_files, forged_files, writers = verify_dataset(
    CONFIG['genuine_dir'],
    CONFIG['forged_dir']
)

# **Visualization - Genuine vs Forged Samples**

def visualize_genuine_vs_forged(genuine_dir, forged_dir, num_samples=3):
    """
    Display genuine signatures with their corresponding forgeries

    Args:
        genuine_dir: Path to genuine signatures
        forged_dir: Path to forged signatures
        num_samples: Number of writer samples to display
    """

    # Get list of files
    genuine_files = sorted([f for f in os.listdir(genuine_dir) if f.endswith('.png')])
    forged_files = sorted([f for f in os.listdir(forged_dir) if f.endswith('.png')])

    # Debug: Show sample filenames
    print("Sample genuine filename:", genuine_files[0] if genuine_files else "None")
    print("Sample forged filename:", forged_files[0] if forged_files else "None")
    print(f"Total genuine: {len(genuine_files)}, Total forged: {len(forged_files)}\n")

    # Build a dictionary mapping (writer_id, sample_id) to filenames
    genuine_dict = {}
    for f in genuine_files:
        # Handle format: original_X_Y.png
        name = f.replace('.png', '')
        parts = name.split('_')
        if len(parts) >= 3:
            try:
                writer_id = int(parts[1])
                sample_id = int(parts[2])
                genuine_dict[(writer_id, sample_id)] = f
            except ValueError:
                continue

    forged_dict = {}
    for f in forged_files:
        # Handle format: forgeries_X_Y.png
        name = f.replace('.png', '')
        parts = name.split('_')
        if len(parts) >= 3:
            try:
                writer_id = int(parts[1])
                sample_id = int(parts[2])
                forged_dict[(writer_id, sample_id)] = f
            except ValueError:
                continue

    # Find matching pairs (same writer_id and sample_id)
    matching_keys = list(set(genuine_dict.keys()) & set(forged_dict.keys()))

    print(f"Found {len(matching_keys)} matching genuine-forged pairs")

    if len(matching_keys) == 0:
        print("\nNo matching pairs found!")
        print("Checking file patterns...")
        print(f"Genuine keys sample: {list(genuine_dict.keys())[:5]}")
        print(f"Forged keys sample: {list(forged_dict.keys())[:5]}")
        return

    # Select random pairs
    selected_keys = random.sample(matching_keys, min(num_samples, len(matching_keys)))

    # Create figure
    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 4 * num_samples))
    fig.suptitle('Genuine Signatures vs Forged Signatures', fontsize=16, fontweight='bold')

    # Handle single row case
    if num_samples == 1:
        axes = axes.reshape(1, -1)

    for row, (writer_id, sample_id) in enumerate(selected_keys):
        genuine_filename = genuine_dict[(writer_id, sample_id)]
        forged_filename = forged_dict[(writer_id, sample_id)]

        # Full paths
        genuine_path = os.path.join(genuine_dir, genuine_filename)
        forged_path = os.path.join(forged_dir, forged_filename)

        # Load images
        genuine_img = cv2.imread(genuine_path, cv2.IMREAD_GRAYSCALE)
        forged_img = cv2.imread(forged_path, cv2.IMREAD_GRAYSCALE)

        # Display genuine
        if genuine_img is not None:
            axes[row, 0].imshow(genuine_img, cmap='gray')
            axes[row, 0].set_title(f'Genuine (Writer {writer_id}, Sample {sample_id})',
                                   color='green', fontsize=12, fontweight='bold')
        else:
            axes[row, 0].text(0.5, 0.5, f'Could not load\n{genuine_filename}',
                             ha='center', va='center', fontsize=10)
            axes[row, 0].set_title('Genuine - Load Error', color='orange')
        axes[row, 0].axis('off')

        # Display forged
        if forged_img is not None:
            axes[row, 1].imshow(forged_img, cmap='gray')
            axes[row, 1].set_title(f'Forged (Writer {writer_id}, Sample {sample_id})',
                                   color='red', fontsize=12, fontweight='bold')
        else:
            axes[row, 1].text(0.5, 0.5, f'Could not load\n{forged_filename}',
                             ha='center', va='center', fontsize=10)
            axes[row, 1].set_title('Forged - Load Error', color='orange')
        axes[row, 1].axis('off')

    plt.tight_layout()
    plt.show()

    print(f"\nDisplayed {num_samples} genuine-forged signature pairs")
    print("Notice the subtle differences between genuine and forged signatures")

# Run visualization
visualize_genuine_vs_forged(CONFIG['genuine_dir'], CONFIG['forged_dir'], num_samples=3)

# **Image Preprocessing Functions**

def preprocess_signature(img_path, target_size=(150, 220)):
    """
    Preprocess a signature image using OpenCV

    Pipeline:
    1. Load grayscale
    2. Apply Gaussian blur
    3. Otsu's thresholding
    4. Resize to target size
    5. Convert to PIL Image

    Args:
        img_path: Path to image file
        target_size: (height, width) tuple

    Returns:
        PIL Image (mode 'L' for grayscale)
    """
    # Load as grayscale
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

    if img is None:
        raise ValueError(f"Could not load image: {img_path}")

    # Apply Gaussian blur to reduce noise
    img = cv2.GaussianBlur(img, (5, 5), 0)

    # Otsu's thresholding for binarization
    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Resize to target size (width, height for cv2)
    img = cv2.resize(img, (target_size[1], target_size[0]),
                     interpolation=cv2.INTER_AREA)

    # Convert to PIL Image
    pil_img = Image.fromarray(img)

    return pil_img


def load_image_raw(img_path):
    # Load raw image as PIL for comparison visualization
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    return Image.fromarray(img)


print("Preprocessing functions defined")
print("Pipeline: Load → Blur → Threshold → Resize → PIL")

# **Cedar Signature Dataset Class**

class CedarSignatureDataset(data.Dataset):
    """
    Cedar Signature Dataset for verification task

    Following curriculum pattern:
    - Inherits from data.Dataset
    - Implements __init__, __len__, __getitem__
    """

    def __init__(self, file_list, img_size=(150, 220), transform=None):
        """
        Initialize the dataset

        Args:
            file_list: List of tuples (file_path, label)
            img_size: Target image size (height, width)
            transform: Optional torchvision transforms
        """
        super().__init__()
        self.file_list = file_list
        self.img_size = img_size
        self.transform = transform
        self.size = len(file_list)

    def __len__(self):
        # Return dataset size
        return self.size

    def __getitem__(self, idx):
        """
        Get a single sample

        Returns:
            data_point: Image tensor
            data_label: Label tensor (0=forged, 1=genuine)
        """
        img_path, label = self.file_list[idx]

        # Preprocess image (returns PIL Image)
        img = preprocess_signature(img_path, self.img_size)

        # Apply transforms if provided
        if self.transform:
            data_point = self.transform(img)
        else:
            # Default: convert to tensor and normalize
            data_point = transforms.ToTensor()(img)

        # Convert label to tensor
        data_label = torch.tensor(label, dtype=torch.long)

        return data_point, data_label


print("CedarSignatureDataset class defined")
print("Following curriculum pattern: __init__, __len__, __getitem__")

# **Define Transforms**

# Training transforms (with augmentation)
train_transform = transforms.Compose([
    transforms.RandomAffine(
        degrees=5,           # Small rotation
        translate=(0.05, 0.05),  # Small translation
        scale=(0.95, 1.05),  # Small scaling
        fill=255             # White fill for signature images
    ),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]
])

# Validation/Test transforms (no augmentation)
val_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

print("Transforms defined:")
print("- Training: Affine augmentation + Normalize")
print("- Validation/Test: Normalize only")

# **Create Writer-Independent Splits**

def create_splits(genuine_dir, forged_dir, writers, train_ratio=0.7, val_ratio=0.15):
    """
    Create train/val/test splits by writer (writer-independent)

    Args:
        genuine_dir: Path to genuine signatures
        forged_dir: Path to forged signatures
        writers: List of writer IDs
        train_ratio: Proportion for training
        val_ratio: Proportion for validation

    Returns:
        Dictionary with train/val/test file lists
    """
    # Shuffle writers
    writers_shuffled = writers.copy()
    random.shuffle(writers_shuffled)

    # Calculate split points
    n_writers = len(writers_shuffled)
    n_train = int(n_writers * train_ratio)
    n_val = int(n_writers * val_ratio)

    # Split writers
    train_writers = set(writers_shuffled[:n_train])
    val_writers = set(writers_shuffled[n_train:n_train + n_val])
    test_writers = set(writers_shuffled[n_train + n_val:])

    print(f"Writers split: Train={len(train_writers)}, Val={len(val_writers)}, Test={len(test_writers)}")

    # Collect files for each split
    splits = {'train': [], 'val': [], 'test': []}

    # Process genuine signatures (label=1)
    for filename in os.listdir(genuine_dir):
        if not filename.endswith('.png'):
            continue
        parts = filename.replace('.png', '').split('_')
        if len(parts) >= 2:
            writer_id = int(parts[1])
            file_path = os.path.join(genuine_dir, filename)

            if writer_id in train_writers:
                splits['train'].append((file_path, 1))
            elif writer_id in val_writers:
                splits['val'].append((file_path, 1))
            else:
                splits['test'].append((file_path, 1))

    # Process forged signatures (label=0)
    for filename in os.listdir(forged_dir):
        if not filename.endswith('.png'):
            continue
        parts = filename.replace('.png', '').split('_')
        if len(parts) >= 2:
            writer_id = int(parts[1])
            file_path = os.path.join(forged_dir, filename)

            if writer_id in train_writers:
                splits['train'].append((file_path, 0))
            elif writer_id in val_writers:
                splits['val'].append((file_path, 0))
            else:
                splits['test'].append((file_path, 0))

    # Shuffle each split
    for key in splits:
        random.shuffle(splits[key])

    # Store writer assignments
    splits['writer_assignments'] = {
        'train': sorted(train_writers),
        'val': sorted(val_writers),
        'test': sorted(test_writers)
    }

    return splits

# Create splits
splits = create_splits(
    CONFIG['genuine_dir'],
    CONFIG['forged_dir'],
    writers,
    CONFIG['train_ratio'],
    CONFIG['val_ratio']
)

print(f"\nSplit sizes:")
print(f"  Train: {len(splits['train'])} samples")
print(f"  Val:   {len(splits['val'])} samples")
print(f"  Test:  {len(splits['test'])} samples")

# **Create Dataset Instances**

# Create datasets
train_dataset = CedarSignatureDataset(
    splits['train'],
    img_size=CONFIG['img_size'],
    transform=train_transform
)

val_dataset = CedarSignatureDataset(
    splits['val'],
    img_size=CONFIG['img_size'],
    transform=val_transform
)

test_dataset = CedarSignatureDataset(
    splits['test'],
    img_size=CONFIG['img_size'],
    transform=val_transform
)

print("Datasets created:")
print(f"  train_dataset: {len(train_dataset)} samples")
print(f"  val_dataset:   {len(val_dataset)} samples")
print(f"  test_dataset:  {len(test_dataset)} samples")

# **DataLoaders Creation**

train_loader = data.DataLoader(
    train_dataset,
    batch_size=CONFIG['batch_size'],
    shuffle=True,
    num_workers=CONFIG['num_workers'],
    pin_memory=True if torch.cuda.is_available() else False,
    drop_last=True
)

val_loader = data.DataLoader(
    val_dataset,
    batch_size=CONFIG['batch_size'],
    shuffle=False,
    num_workers=CONFIG['num_workers'],
    pin_memory=True if torch.cuda.is_available() else False
)

test_loader = data.DataLoader(
    test_dataset,
    batch_size=CONFIG['batch_size'],
    shuffle=False,
    num_workers=CONFIG['num_workers'],
    pin_memory=True if torch.cuda.is_available() else False
)

print("DataLoaders created:")
print(f"  train_loader: {len(train_loader)} batches")
print(f"  val_loader:   {len(val_loader)} batches")
print(f"  test_loader:  {len(test_loader)} batches")
print(f"\nBatch size: {CONFIG['batch_size']}")

# **Dataset Statistics**

def compute_statistics(splits):
    # Compute class distribution for each split

    print("=" * 50)
    print("DATASET STATISTICS")
    print("=" * 50)

    for split_name in ['train', 'val', 'test']:
        samples = splits[split_name]
        genuine = sum(1 for _, label in samples if label == 1)
        forged = sum(1 for _, label in samples if label == 0)
        total = len(samples)

        print(f"\n{split_name.upper()}:")
        print(f"  Genuine: {genuine} ({100*genuine/total:.1f}%)")
        print(f"  Forged:  {forged} ({100*forged/total:.1f}%)")
        print(f"  Total:   {total}")

compute_statistics(splits)
